{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "d57b7666-214b-474a-adbc-542e72d94066",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "64c505db-aaed-4d3f-908d-537df4352fd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time (ET)</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Favorite</th>\n",
       "      <th>Score</th>\n",
       "      <th>Spread</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Notes</th>\n",
       "      <th>GameHub/RedZone</th>\n",
       "      <th>Game thread link?</th>\n",
       "      <th>Post-game thread link?</th>\n",
       "      <th>Game thread</th>\n",
       "      <th>Post game thread</th>\n",
       "      <th>GameHub Scraped</th>\n",
       "      <th>Game thread scraped</th>\n",
       "      <th>Post game thread Scraped</th>\n",
       "      <th>Subscribers (in thousands)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2017-09-07</td>\n",
       "      <td>8:30</td>\n",
       "      <td>@</td>\n",
       "      <td>New England Patriots</td>\n",
       "      <td>L 27-42</td>\n",
       "      <td>L -8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6yr619/g...</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6ysc10/p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[3193, ('Dear Falcons fans: are you guys ready...</td>\n",
       "      <td>[2781, ('I\\'m imagining a world where the Patr...</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>1:00</td>\n",
       "      <td>@</td>\n",
       "      <td>Buffalo Bills</td>\n",
       "      <td>W 21-12</td>\n",
       "      <td>W -7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6z90qu/g...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6z97il/g...</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6zajs1/p...</td>\n",
       "      <td>[240, ('Bitter-sweet start to the NFL season w...</td>\n",
       "      <td>[109, ('I\\'m a Jets fan. I\\'m a Texas A&amp;M fan....</td>\n",
       "      <td>[120, ('Bills number 1 seed in the AFCE!', 194...</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>1:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlanta Falcons</td>\n",
       "      <td>W 23-17</td>\n",
       "      <td>L -6.5</td>\n",
       "      <td>@</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6z90qu/g...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6z97gn/g...</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6zajuc/p...</td>\n",
       "      <td>[240, ('Bitter-sweet start to the NFL season w...</td>\n",
       "      <td>[321, ('Wow this national anthem singer is a f...</td>\n",
       "      <td>[351, (\"We just went down to the wire against ...</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>1:00</td>\n",
       "      <td>@</td>\n",
       "      <td>Cincinnati Bengals</td>\n",
       "      <td>L 0-20</td>\n",
       "      <td>L -2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6z90qu/g...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6z97hl/g...</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6zajr0/p...</td>\n",
       "      <td>[240, ('Bitter-sweet start to the NFL season w...</td>\n",
       "      <td>[192, (\"Man I hope Woodhead stays healthy for ...</td>\n",
       "      <td>[293, ('[Summary of this game](https://pbs.twi...</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>1:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pittsburgh Steelers</td>\n",
       "      <td>W 21-18</td>\n",
       "      <td>L -10</td>\n",
       "      <td>@</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6z90qu/g...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6z97l9/g...</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6zajwi/p...</td>\n",
       "      <td>[240, ('Bitter-sweet start to the NFL season w...</td>\n",
       "      <td>[367, (\"1 drive no turnovers. WE'VE TURNED THE...</td>\n",
       "      <td>[383, (\"Don't let this distract you from the f...</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  Week  Day       Date Time (ET) Unnamed: 5              Favorite  \\\n",
       "0    2017     1  Thu 2017-09-07      8:30          @  New England Patriots   \n",
       "1    2017     1  Sun 2017-09-10      1:00          @         Buffalo Bills   \n",
       "2    2017     1  Sun 2017-09-10      1:00        NaN       Atlanta Falcons   \n",
       "3    2017     1  Sun 2017-09-10      1:00          @    Cincinnati Bengals   \n",
       "4    2017     1  Sun 2017-09-10      1:00        NaN   Pittsburgh Steelers   \n",
       "\n",
       "     Score  Spread Unnamed: 9  ... Notes  \\\n",
       "0  L 27-42    L -8        NaN  ...   NaN   \n",
       "1  W 21-12    W -7        NaN  ...   NaN   \n",
       "2  W 23-17  L -6.5          @  ...   NaN   \n",
       "3   L 0-20  L -2.5        NaN  ...   NaN   \n",
       "4  W 21-18   L -10          @  ...   NaN   \n",
       "\n",
       "                                     GameHub/RedZone Game thread link?  \\\n",
       "0                                                NaN               NaN   \n",
       "1  https://www.reddit.com/r/nfl/comments/6z90qu/g...               NaN   \n",
       "2  https://www.reddit.com/r/nfl/comments/6z90qu/g...               NaN   \n",
       "3  https://www.reddit.com/r/nfl/comments/6z90qu/g...               NaN   \n",
       "4  https://www.reddit.com/r/nfl/comments/6z90qu/g...               NaN   \n",
       "\n",
       "  Post-game thread link?                                        Game thread  \\\n",
       "0                    NaN  https://www.reddit.com/r/nfl/comments/6yr619/g...   \n",
       "1                    1.0  https://www.reddit.com/r/nfl/comments/6z97il/g...   \n",
       "2                    1.0  https://www.reddit.com/r/nfl/comments/6z97gn/g...   \n",
       "3                    1.0  https://www.reddit.com/r/nfl/comments/6z97hl/g...   \n",
       "4                    1.0  https://www.reddit.com/r/nfl/comments/6z97l9/g...   \n",
       "\n",
       "                                    Post game thread  \\\n",
       "0  https://www.reddit.com/r/nfl/comments/6ysc10/p...   \n",
       "1  https://www.reddit.com/r/nfl/comments/6zajs1/p...   \n",
       "2  https://www.reddit.com/r/nfl/comments/6zajuc/p...   \n",
       "3  https://www.reddit.com/r/nfl/comments/6zajr0/p...   \n",
       "4  https://www.reddit.com/r/nfl/comments/6zajwi/p...   \n",
       "\n",
       "                                     GameHub Scraped  \\\n",
       "0                                                NaN   \n",
       "1  [240, ('Bitter-sweet start to the NFL season w...   \n",
       "2  [240, ('Bitter-sweet start to the NFL season w...   \n",
       "3  [240, ('Bitter-sweet start to the NFL season w...   \n",
       "4  [240, ('Bitter-sweet start to the NFL season w...   \n",
       "\n",
       "                                 Game thread scraped  \\\n",
       "0  [3193, ('Dear Falcons fans: are you guys ready...   \n",
       "1  [109, ('I\\'m a Jets fan. I\\'m a Texas A&M fan....   \n",
       "2  [321, ('Wow this national anthem singer is a f...   \n",
       "3  [192, (\"Man I hope Woodhead stays healthy for ...   \n",
       "4  [367, (\"1 drive no turnovers. WE'VE TURNED THE...   \n",
       "\n",
       "                            Post game thread Scraped  \\\n",
       "0  [2781, ('I\\'m imagining a world where the Patr...   \n",
       "1  [120, ('Bills number 1 seed in the AFCE!', 194...   \n",
       "2  [351, (\"We just went down to the wire against ...   \n",
       "3  [293, ('[Summary of this game](https://pbs.twi...   \n",
       "4  [383, (\"Don't let this distract you from the f...   \n",
       "\n",
       "  Subscribers (in thousands)  \n",
       "0                        640  \n",
       "1                        640  \n",
       "2                        640  \n",
       "3                        640  \n",
       "4                        640  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with zipfile.ZipFile(\"../data/reddit_scrape.csv.zip\") as z:\n",
    "    with z.open(\"reddit_scrape.csv\") as f:\n",
    "        reddit_df = pd.read_csv(f)\n",
    "\n",
    "reddit_df['Date'] = pd.to_datetime(reddit_df['Date'])    \n",
    "reddit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "4b970f37-39db-42b7-ab62-85c0737ee01c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scrape_cols = [x for x in reddit_df.columns if 'craped' in x]\n",
    "for col in scrape_cols: # converts strings to lists\n",
    "    reddit_df[col] = reddit_df[col].apply(lambda x: eval(x) if type(x)==str else x)\n",
    "\n",
    "    \n",
    "reddit_df['game_thread_comments'] = [lst[1:] for lst in reddit_df.loc[:,'Game thread scraped']]\n",
    "reddit_df['post_game_thread_comments'] = [lst[1:] if type(lst)==list else lst for lst in reddit_df.loc[:,'Post game thread Scraped']]\n",
    "reddit_df['all comments'] =  reddit_df['game_thread_comments'] + reddit_df['post_game_thread_comments']\n",
    "reddit_df.loc[reddit_df['all comments'].isna(),'all comments'] = \\\n",
    "        reddit_df.loc[reddit_df['all comments'].isna(),'Game thread scraped']\n",
    "reddit_df.drop(columns=['game_thread_comments','post_game_thread_comments'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "9772ce21-6e95-445e-a475-5a8d4667ddb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dear Falcons fans: are you guys ready for 17 straight weeks of hearing how you fucked up the Super Bowl? I feel your pain. \\n\\nSincerely, \\n\\n\\nSeahawks fans everywhere.'"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = reddit_df['Game thread scraped'][0][1][0]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "810ee356-ef80-412e-ab39-6e744c46b7ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dear Falcons fans: are you guys ready for 17 straight weeks of hearing how you fucked up the Super Bowl? I feel your pain. Sincerely, Seahawks fans everywhere.'"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from markdown import Markdown\n",
    "from io import StringIO\n",
    "\n",
    "\n",
    "def unmark_element(element, stream=None):\n",
    "    if stream is None:\n",
    "        stream = StringIO()\n",
    "    if element.text:\n",
    "        stream.write(element.text)\n",
    "    for sub in element:\n",
    "        unmark_element(sub, stream)\n",
    "    if element.tail:\n",
    "        stream.write(element.tail)\n",
    "    return stream.getvalue()\n",
    "\n",
    "\n",
    "# patching Markdown\n",
    "Markdown.output_formats[\"plain\"] = unmark_element\n",
    "__md = Markdown(output_format=\"plain\")\n",
    "__md.stripTopLevelTags = False\n",
    "\n",
    "\n",
    "def unmark(text):\n",
    "    return __md.convert(text).replace(\" \\n\",\" \")\n",
    "\n",
    "text = unmark(text).replace(\" \\n\",\" \")\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "270f197d-eaf5-4f9f-a449-e163043dd3c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dear Falcons fans are you guys ready for 17 straight weeks of hearing how you fucked up the Super Bowl I feel your pain Sincerely Seahawks fans everywhere'"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "d348f4ad-c29f-41b4-86e6-f2d50858d561",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m202.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /Users/rohanjha/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from vaderSentiment) (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/rohanjha/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from requests->vaderSentiment) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rohanjha/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from requests->vaderSentiment) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/rohanjha/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from requests->vaderSentiment) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rohanjha/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from requests->vaderSentiment) (2022.12.7)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "bc94fff5-0b4f-40e5-912e-ec836ec09015",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "5212fb01-3e98-4894-80b3-21b5ddb68ae2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sentiment_scores(sentence):\n",
    "    # Create a SentimentIntensityAnalyzer object.\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "    # polarity_scores method of SentimentIntensityAnalyzer\n",
    "    # oject gives a sentiment dictionary.\n",
    "    # which contains pos, neg, neu, and compound scores.\n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "    print(\"Overall sentiment dictionary is : \", sentiment_dict)\n",
    "    print(\"sentence was rated as \", sentiment_dict['neg']*100, \"% Negative\")\n",
    "    print(\"sentence was rated as \", sentiment_dict['neu']*100, \"% Neutral\")\n",
    "    print(\"sentence was rated as \", sentiment_dict['pos']*100, \"% Positive\")\n",
    "    print(\"Sentence Overall Rated As\", end = \" \")\n",
    "    # decide sentiment as positive, negative and neutral\n",
    "    if sentiment_dict['compound'] >= 0.05 :\n",
    "        print(\"Positive\")\n",
    "    elif sentiment_dict['compound'] <= - 0.05 :\n",
    "        print(\"Negative\")\n",
    "    else :\n",
    "        print(\"Neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "7cf38b27-677a-44b0-96bc-d44d7bf60b2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall sentiment dictionary is :  {'neg': 0.18, 'neu': 0.492, 'pos': 0.328, 'compound': 0.6486}\n",
      "sentence was rated as  18.0 % Negative\n",
      "sentence was rated as  49.2 % Neutral\n",
      "sentence was rated as  32.800000000000004 % Positive\n",
      "Sentence Overall Rated As Positive\n"
     ]
    }
   ],
   "source": [
    "sentiment_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "6880eb6b-21df-45f6-8ee1-cb8798c600f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Fuckin Mark Wahlberg LEFT THE SUPER BOWL EARLY BECAUSE THE PATS WERE DOWN 28-3\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 0.737, 'pos': 0.263, 'compound': 0.6841}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  73.7 % Neutral\n",
      "sentence was rated as  26.3 % Positive\n",
      "Sentence Overall Rated As Positive\n"
     ]
    }
   ],
   "source": [
    "text = reddit_df['Game thread scraped'][0][2][0]\n",
    "print(text)\n",
    "text = unmark(text).replace(\" \\n\",\" \")\n",
    "text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "sentiment_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "9daea5bb-5f7f-49ca-943d-f4313ca6df89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SuperBowl is a great event.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def convert_super_bowl(text):\n",
    "    # Use regular expression to find and replace \"super bowl\" with \"superbowl\" (case-insensitive)\n",
    "    modified_text = re.sub(r'\\b(super)\\s+(bowl)\\b', r'\\1\\2', text, flags=re.IGNORECASE)\n",
    "    return modified_text\n",
    "\n",
    "# Example usage:\n",
    "original_text = \"The Super Bowl is a great event.\"\n",
    "converted_text = convert_super_bowl(original_text)\n",
    "print(converted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "c81fda98-6cc0-4330-82ad-98e5701741d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "thread_num = []\n",
    "comment_num = []\n",
    "comments = []\n",
    "pos_words = []\n",
    "neu_words = []\n",
    "neg_words = []\n",
    "scores = []\n",
    "# overall_rating = []\n",
    "\n",
    "for i in range(10):\n",
    "    num_1 = random.randrange(len(reddit_df))\n",
    "    for j in range(50):\n",
    "        thread_num.append(num_1)\n",
    "        num_2 = random.randrange(len(reddit_df.iloc[num_1,:].loc['Game thread scraped']))\n",
    "        if j != 0:\n",
    "            while num_2 in comment_num[-j:]:\n",
    "                num_2 = random.randrange(len(reddit_df.iloc[num_1,:].loc['Game thread scraped']))\n",
    "        comment_num.append(num_2)\n",
    "        text = reddit_df['Game thread scraped'][num_1][num_2][0]\n",
    "        # print(text)\n",
    "        # print(\"____________________________________________________________________________________________________\")\n",
    "        comments.append(text)\n",
    "        text = unmark(text).replace(\" \\n\",\" \")\n",
    "        text = convert_super_bowl(text)\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "        from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "        tokenized_sentence = nltk.word_tokenize(text)\n",
    "\n",
    "        sid = SentimentIntensityAnalyzer()\n",
    "        pos_word_list=[]\n",
    "        neu_word_list=[]\n",
    "        neg_word_list=[]\n",
    "\n",
    "        for word in tokenized_sentence:\n",
    "            if (sid.polarity_scores(word)['compound']) >= 0.05:\n",
    "                pos_word_list.append(word)\n",
    "            elif (sid.polarity_scores(word)['compound']) <= -0.05:\n",
    "                neg_word_list.append(word)\n",
    "            else:\n",
    "                neu_word_list.append(word)                \n",
    "\n",
    "        # print('Positive:', pos_word_list) \n",
    "        pos_words.append(pos_word_list)\n",
    "        # print('Neutral:', neu_word_list) \n",
    "        neu_words.append(neu_word_list)\n",
    "        # print('Negative:', neg_word_list) \n",
    "        neg_words.append(neg_word_list)\n",
    "        score = sid.polarity_scores(text)\n",
    "        # print('\\nScores:', score,\"\\n\")\n",
    "        scores.append(score)\n",
    "        # print(\"Sentence Overall Rated As\", end = \" \")\n",
    "        # if score['compound'] >= 0.05 :\n",
    "        #     # print(\"Positive\")\n",
    "        #     overall_rating.append(1)\n",
    "        # elif score['compound'] <= - 0.05 :\n",
    "        #     # print(\"Negative\")\n",
    "        #     overall_rating.append(-1)\n",
    "        # else :\n",
    "        #     # print(\"Neutral\")\n",
    "        #     overall_rating.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "f001525f-d093-4116-bb5f-6d798fc0196b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Thread</th>\n",
       "      <th>Comment Number</th>\n",
       "      <th>Comment Text</th>\n",
       "      <th>Positive Words</th>\n",
       "      <th>Neutral Words</th>\n",
       "      <th>Negative Words</th>\n",
       "      <th>Scores</th>\n",
       "      <th>Overall Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220</td>\n",
       "      <td>251</td>\n",
       "      <td>He broke crossed the line and had control. How...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[He, crossed, the, line, and, had, control, Ho...</td>\n",
       "      <td>[broke, lose]</td>\n",
       "      <td>{'neg': 0.103, 'neu': 0.813, 'pos': 0.083, 'co...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220</td>\n",
       "      <td>396</td>\n",
       "      <td>There were multiple Patriots not lined up prop...</td>\n",
       "      <td>[play, like]</td>\n",
       "      <td>[There, were, multiple, Patriots, not, lined, ...</td>\n",
       "      <td>[miss]</td>\n",
       "      <td>{'neg': 0.056, 'neu': 0.772, 'pos': 0.172, 'co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220</td>\n",
       "      <td>52</td>\n",
       "      <td>THIS WEEK ON WHAT IS A CATCH</td>\n",
       "      <td>[]</td>\n",
       "      <td>[THIS, WEEK, ON, WHAT, IS, A, CATCH]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220</td>\n",
       "      <td>420</td>\n",
       "      <td>8 is neither 5 or 6. Good job D.</td>\n",
       "      <td>[Good]</td>\n",
       "      <td>[8, is, neither, 5, or, 6, job, D]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'neg': 0.376, 'neu': 0.624, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220</td>\n",
       "      <td>283</td>\n",
       "      <td>That's a catch. Don't care what the rules say.</td>\n",
       "      <td>[care]</td>\n",
       "      <td>[Thats, a, catch, Dont, what, the, rules, say]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'neg': 0.273, 'neu': 0.727, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>55</td>\n",
       "      <td>189</td>\n",
       "      <td>Wanna know what's gonna happen? Carolina is go...</td>\n",
       "      <td>[win]</td>\n",
       "      <td>[Wan, na, know, whats, gon, na, happen, Caroli...</td>\n",
       "      <td>[fuck, wrong, forgotten]</td>\n",
       "      <td>{'neg': 0.134, 'neu': 0.806, 'pos': 0.06, 'com...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>55</td>\n",
       "      <td>403</td>\n",
       "      <td>I'm loving these TD celebrations. Glad they're...</td>\n",
       "      <td>[loving, Glad]</td>\n",
       "      <td>[Im, these, TD, celebrations, theyre, back]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.465, 'pos': 0.535, 'comp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>Love this hate Patriot fans.</td>\n",
       "      <td>[Love]</td>\n",
       "      <td>[this, Patriot, fans]</td>\n",
       "      <td>[hate]</td>\n",
       "      <td>{'neg': 0.339, 'neu': 0.275, 'pos': 0.385, 'co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>55</td>\n",
       "      <td>215</td>\n",
       "      <td>STEPHEN GOSTKOWSKI IS STILL PERFECT THIS MONTH!</td>\n",
       "      <td>[PERFECT]</td>\n",
       "      <td>[STEPHEN, GOSTKOWSKI, IS, STILL, THIS, MONTH]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.619, 'pos': 0.381, 'comp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>55</td>\n",
       "      <td>281</td>\n",
       "      <td>Late hits are okay. Touching anyone in passing...</td>\n",
       "      <td>[okay, plays]</td>\n",
       "      <td>[Late, hits, are, Touching, anyone, in, passin...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.698, 'pos': 0.302, 'comp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Thread  Comment Number  \\\n",
       "0       220             251   \n",
       "1       220             396   \n",
       "2       220              52   \n",
       "3       220             420   \n",
       "4       220             283   \n",
       "..      ...             ...   \n",
       "495      55             189   \n",
       "496      55             403   \n",
       "497      55              50   \n",
       "498      55             215   \n",
       "499      55             281   \n",
       "\n",
       "                                          Comment Text  Positive Words  \\\n",
       "0    He broke crossed the line and had control. How...              []   \n",
       "1    There were multiple Patriots not lined up prop...    [play, like]   \n",
       "2                        THIS WEEK ON WHAT IS A CATCH               []   \n",
       "3                     8 is neither 5 or 6. Good job D.          [Good]   \n",
       "4       That's a catch. Don't care what the rules say.          [care]   \n",
       "..                                                 ...             ...   \n",
       "495  Wanna know what's gonna happen? Carolina is go...           [win]   \n",
       "496  I'm loving these TD celebrations. Glad they're...  [loving, Glad]   \n",
       "497                       Love this hate Patriot fans.          [Love]   \n",
       "498    STEPHEN GOSTKOWSKI IS STILL PERFECT THIS MONTH!       [PERFECT]   \n",
       "499  Late hits are okay. Touching anyone in passing...   [okay, plays]   \n",
       "\n",
       "                                         Neutral Words  \\\n",
       "0    [He, crossed, the, line, and, had, control, Ho...   \n",
       "1    [There, were, multiple, Patriots, not, lined, ...   \n",
       "2                 [THIS, WEEK, ON, WHAT, IS, A, CATCH]   \n",
       "3                   [8, is, neither, 5, or, 6, job, D]   \n",
       "4       [Thats, a, catch, Dont, what, the, rules, say]   \n",
       "..                                                 ...   \n",
       "495  [Wan, na, know, whats, gon, na, happen, Caroli...   \n",
       "496        [Im, these, TD, celebrations, theyre, back]   \n",
       "497                              [this, Patriot, fans]   \n",
       "498      [STEPHEN, GOSTKOWSKI, IS, STILL, THIS, MONTH]   \n",
       "499  [Late, hits, are, Touching, anyone, in, passin...   \n",
       "\n",
       "               Negative Words  \\\n",
       "0               [broke, lose]   \n",
       "1                      [miss]   \n",
       "2                          []   \n",
       "3                          []   \n",
       "4                          []   \n",
       "..                        ...   \n",
       "495  [fuck, wrong, forgotten]   \n",
       "496                        []   \n",
       "497                    [hate]   \n",
       "498                        []   \n",
       "499                        []   \n",
       "\n",
       "                                                Scores  Overall Rating  \n",
       "0    {'neg': 0.103, 'neu': 0.813, 'pos': 0.083, 'co...              -1  \n",
       "1    {'neg': 0.056, 'neu': 0.772, 'pos': 0.172, 'co...               1  \n",
       "2    {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...               0  \n",
       "3    {'neg': 0.376, 'neu': 0.624, 'pos': 0.0, 'comp...              -1  \n",
       "4    {'neg': 0.273, 'neu': 0.727, 'pos': 0.0, 'comp...              -1  \n",
       "..                                                 ...             ...  \n",
       "495  {'neg': 0.134, 'neu': 0.806, 'pos': 0.06, 'com...              -1  \n",
       "496  {'neg': 0.0, 'neu': 0.465, 'pos': 0.535, 'comp...               1  \n",
       "497  {'neg': 0.339, 'neu': 0.275, 'pos': 0.385, 'co...               1  \n",
       "498  {'neg': 0.0, 'neu': 0.619, 'pos': 0.381, 'comp...               1  \n",
       "499  {'neg': 0.0, 'neu': 0.698, 'pos': 0.302, 'comp...               1  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"Thread\": thread_num,\n",
    "    \"Comment Number\": comment_num,\n",
    "    'Comment Text': comments,\n",
    "    'Positive Words': pos_words,\n",
    "    'Neutral Words': neu_words,\n",
    "    'Negative Words': neg_words,\n",
    "    'Scores': scores,\n",
    "    'Overall Rating': overall_rating\n",
    "}\n",
    "\n",
    "verifying_df = pd.DataFrame(data)\n",
    "verifying_df#.to_csv('verifying_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "a12afac8-1ff5-4b0b-a20b-7c68417faab6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.0     0.521053\n",
      " 0.0     0.247368\n",
      "-0.5     0.110526\n",
      "-99.0    0.094737\n",
      " 0.5     0.026316\n",
      "Name: Accurate, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Thread</th>\n",
       "      <th>Comment Number</th>\n",
       "      <th>Comment Text</th>\n",
       "      <th>Positive Words</th>\n",
       "      <th>Neutral Words</th>\n",
       "      <th>Negative Words</th>\n",
       "      <th>Scores</th>\n",
       "      <th>My rating</th>\n",
       "      <th>Compound</th>\n",
       "      <th>Overall Rating</th>\n",
       "      <th>Accurate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220</td>\n",
       "      <td>251</td>\n",
       "      <td>He broke crossed the line and had control. How...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['He', 'crossed', 'the', 'line', 'and', 'had',...</td>\n",
       "      <td>['broke', 'lose']</td>\n",
       "      <td>{'neg': 0.103, 'neu': 0.813, 'pos': 0.083, 'co...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.1386</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220</td>\n",
       "      <td>396</td>\n",
       "      <td>There were multiple Patriots not lined up prop...</td>\n",
       "      <td>['play', 'like']</td>\n",
       "      <td>['There', 'were', 'multiple', 'Patriots', 'not...</td>\n",
       "      <td>['miss']</td>\n",
       "      <td>{'neg': 0.056, 'neu': 0.772, 'pos': 0.172, 'co...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220</td>\n",
       "      <td>52</td>\n",
       "      <td>THIS WEEK ON WHAT IS A CATCH</td>\n",
       "      <td>[]</td>\n",
       "      <td>['THIS', 'WEEK', 'ON', 'WHAT', 'IS', 'A', 'CAT...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220</td>\n",
       "      <td>420</td>\n",
       "      <td>8 is neither 5 or 6. Good job D.</td>\n",
       "      <td>['Good']</td>\n",
       "      <td>['8', 'is', 'neither', '5', 'or', '6', 'job', ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'neg': 0.376, 'neu': 0.624, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-0.3412</td>\n",
       "      <td>-1</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220</td>\n",
       "      <td>283</td>\n",
       "      <td>That's a catch. Don't care what the rules say.</td>\n",
       "      <td>['care']</td>\n",
       "      <td>['Thats', 'a', 'catch', 'Dont', 'what', 'the',...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'neg': 0.273, 'neu': 0.727, 'pos': 0.0, 'comp...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.3875</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>55</td>\n",
       "      <td>189</td>\n",
       "      <td>Wanna know what's gonna happen? Carolina is go...</td>\n",
       "      <td>['win']</td>\n",
       "      <td>['Wan', 'na', 'know', 'whats', 'gon', 'na', 'h...</td>\n",
       "      <td>['fuck', 'wrong', 'forgotten']</td>\n",
       "      <td>{'neg': 0.134, 'neu': 0.806, 'pos': 0.06, 'com...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.5719</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>55</td>\n",
       "      <td>403</td>\n",
       "      <td>I'm loving these TD celebrations. Glad they're...</td>\n",
       "      <td>['loving', 'Glad']</td>\n",
       "      <td>['Im', 'these', 'TD', 'celebrations', 'theyre'...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.465, 'pos': 0.535, 'comp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>Love this hate Patriot fans.</td>\n",
       "      <td>['Love']</td>\n",
       "      <td>['this', 'Patriot', 'fans']</td>\n",
       "      <td>['hate']</td>\n",
       "      <td>{'neg': 0.339, 'neu': 0.275, 'pos': 0.385, 'co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>55</td>\n",
       "      <td>215</td>\n",
       "      <td>STEPHEN GOSTKOWSKI IS STILL PERFECT THIS MONTH!</td>\n",
       "      <td>['PERFECT']</td>\n",
       "      <td>['STEPHEN', 'GOSTKOWSKI', 'IS', 'STILL', 'THIS...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.619, 'pos': 0.381, 'comp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>55</td>\n",
       "      <td>281</td>\n",
       "      <td>Late hits are okay. Touching anyone in passing...</td>\n",
       "      <td>['okay', 'plays']</td>\n",
       "      <td>['Late', 'hits', 'are', 'Touching', 'anyone', ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.698, 'pos': 0.302, 'comp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Thread  Comment Number  \\\n",
       "0       220             251   \n",
       "1       220             396   \n",
       "2       220              52   \n",
       "3       220             420   \n",
       "4       220             283   \n",
       "..      ...             ...   \n",
       "485      55             189   \n",
       "486      55             403   \n",
       "487      55              50   \n",
       "488      55             215   \n",
       "489      55             281   \n",
       "\n",
       "                                          Comment Text      Positive Words  \\\n",
       "0    He broke crossed the line and had control. How...                  []   \n",
       "1    There were multiple Patriots not lined up prop...    ['play', 'like']   \n",
       "2                        THIS WEEK ON WHAT IS A CATCH                   []   \n",
       "3                     8 is neither 5 or 6. Good job D.            ['Good']   \n",
       "4       That's a catch. Don't care what the rules say.            ['care']   \n",
       "..                                                 ...                 ...   \n",
       "485  Wanna know what's gonna happen? Carolina is go...             ['win']   \n",
       "486  I'm loving these TD celebrations. Glad they're...  ['loving', 'Glad']   \n",
       "487                       Love this hate Patriot fans.            ['Love']   \n",
       "488    STEPHEN GOSTKOWSKI IS STILL PERFECT THIS MONTH!         ['PERFECT']   \n",
       "489  Late hits are okay. Touching anyone in passing...   ['okay', 'plays']   \n",
       "\n",
       "                                         Neutral Words  \\\n",
       "0    ['He', 'crossed', 'the', 'line', 'and', 'had',...   \n",
       "1    ['There', 'were', 'multiple', 'Patriots', 'not...   \n",
       "2    ['THIS', 'WEEK', 'ON', 'WHAT', 'IS', 'A', 'CAT...   \n",
       "3    ['8', 'is', 'neither', '5', 'or', '6', 'job', ...   \n",
       "4    ['Thats', 'a', 'catch', 'Dont', 'what', 'the',...   \n",
       "..                                                 ...   \n",
       "485  ['Wan', 'na', 'know', 'whats', 'gon', 'na', 'h...   \n",
       "486  ['Im', 'these', 'TD', 'celebrations', 'theyre'...   \n",
       "487                        ['this', 'Patriot', 'fans']   \n",
       "488  ['STEPHEN', 'GOSTKOWSKI', 'IS', 'STILL', 'THIS...   \n",
       "489  ['Late', 'hits', 'are', 'Touching', 'anyone', ...   \n",
       "\n",
       "                     Negative Words  \\\n",
       "0                 ['broke', 'lose']   \n",
       "1                          ['miss']   \n",
       "2                                []   \n",
       "3                                []   \n",
       "4                                []   \n",
       "..                              ...   \n",
       "485  ['fuck', 'wrong', 'forgotten']   \n",
       "486                              []   \n",
       "487                        ['hate']   \n",
       "488                              []   \n",
       "489                              []   \n",
       "\n",
       "                                                Scores  My rating  Compound  \\\n",
       "0    {'neg': 0.103, 'neu': 0.813, 'pos': 0.083, 'co...       -1.0   -0.1386   \n",
       "1    {'neg': 0.056, 'neu': 0.772, 'pos': 0.172, 'co...       -1.0    0.5106   \n",
       "2    {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...        0.0    0.0000   \n",
       "3    {'neg': 0.376, 'neu': 0.624, 'pos': 0.0, 'comp...      -99.0   -0.3412   \n",
       "4    {'neg': 0.273, 'neu': 0.727, 'pos': 0.0, 'comp...        1.0   -0.3875   \n",
       "..                                                 ...        ...       ...   \n",
       "485  {'neg': 0.134, 'neu': 0.806, 'pos': 0.06, 'com...        NaN   -0.5719   \n",
       "486  {'neg': 0.0, 'neu': 0.465, 'pos': 0.535, 'comp...        NaN    0.7845   \n",
       "487  {'neg': 0.339, 'neu': 0.275, 'pos': 0.385, 'co...        NaN    0.1280   \n",
       "488  {'neg': 0.0, 'neu': 0.619, 'pos': 0.381, 'comp...        NaN    0.5719   \n",
       "489  {'neg': 0.0, 'neu': 0.698, 'pos': 0.302, 'comp...        NaN    0.4404   \n",
       "\n",
       "     Overall Rating  Accurate  \n",
       "0                -1       1.0  \n",
       "1                 1       0.0  \n",
       "2                 0       1.0  \n",
       "3                -1     -99.0  \n",
       "4                -1       0.0  \n",
       "..              ...       ...  \n",
       "485              -1       NaN  \n",
       "486               1       NaN  \n",
       "487               1       NaN  \n",
       "488               1       NaN  \n",
       "489               1       NaN  \n",
       "\n",
       "[490 rows x 11 columns]"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('verifying_scores.csv').iloc[:,1:]\n",
    "def cutoffs(lower_bound, upper_bound, col):\n",
    "    lst = []\n",
    "    for i in col:\n",
    "        if i <= lower_bound:\n",
    "            lst.append(-1)\n",
    "        elif i >= upper_bound:\n",
    "            lst.append(1)\n",
    "        else:\n",
    "            lst.append(0)\n",
    "    return lst\n",
    "df['Scores'] = df['Scores'].apply(eval)\n",
    "df['Compound'] = [i['compound'] for i in df['Scores']]\n",
    "df['Overall Rating'] = cutoffs(-0.05, 0.05, df['Compound'])\n",
    "df['Accurate'] = (df['My rating'] == df['Overall Rating']).astype(int)\n",
    "df.loc[(df['Overall Rating'] == 0) & (df['My rating'] != 0), 'Accurate'] = \\\n",
    "    df.loc[(df['Overall Rating'] == 0) & (df['My rating'] != 0), 'My rating']/2\n",
    "df.loc[df['My rating'] == -99, 'Accurate'] = -99\n",
    "df.loc[df['My rating'].isna(), 'Accurate'] = np.NaN\n",
    "print(df.loc[:,'Accurate'].value_counts(normalize=True))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "00d42f9f-cdea-416b-a2fe-5c5f66dfb604",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 220\n",
      "Length: 46\n",
      " 1.0     0.478261\n",
      " 0.0     0.239130\n",
      "-99.0    0.173913\n",
      "-0.5     0.108696\n",
      "Name: Accurate, dtype: float64\n",
      "Index: 424\n",
      "Length: 48\n",
      " 1.0     0.500000\n",
      " 0.0     0.229167\n",
      "-99.0    0.145833\n",
      "-0.5     0.125000\n",
      "Name: Accurate, dtype: float64\n",
      "Index: 603\n",
      "Length: 47\n",
      " 1.0    0.574468\n",
      " 0.0    0.319149\n",
      "-0.5    0.085106\n",
      " 0.5    0.021277\n",
      "Name: Accurate, dtype: float64\n",
      "Index: 416\n",
      "Length: 49\n",
      " 1.0     0.530612\n",
      " 0.0     0.204082\n",
      "-0.5     0.122449\n",
      " 0.5     0.081633\n",
      "-99.0    0.061224\n",
      "Name: Accurate, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for idx in df['Thread'].unique()[:4]:\n",
    "    sub_df = df[df['Thread'] == idx]\n",
    "    print(f\"Index: {idx}\")\n",
    "    print(f\"Length: {len(sub_df)}\")\n",
    "    print(sub_df.loc[:,'Accurate'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763ac362-0b7b-4510-a99b-8ca339f4fabc",
   "metadata": {},
   "source": [
    "## Generating proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "5cdc27eb-6036-441e-a3a8-5b3a77b453a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time (ET)</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Favorite</th>\n",
       "      <th>Score</th>\n",
       "      <th>Spread</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>GameHub/RedZone</th>\n",
       "      <th>Game thread link?</th>\n",
       "      <th>Post-game thread link?</th>\n",
       "      <th>Game thread</th>\n",
       "      <th>Post game thread</th>\n",
       "      <th>GameHub Scraped</th>\n",
       "      <th>Game thread scraped</th>\n",
       "      <th>Post game thread Scraped</th>\n",
       "      <th>Subscribers (in thousands)</th>\n",
       "      <th>all comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2017-09-07</td>\n",
       "      <td>8:30</td>\n",
       "      <td>@</td>\n",
       "      <td>New England Patriots</td>\n",
       "      <td>L 27-42</td>\n",
       "      <td>L -8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6yr619/g...</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6ysc10/p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[3193, (Dear Falcons fans: are you guys ready ...</td>\n",
       "      <td>[2781, (I'm imagining a world where the Patrio...</td>\n",
       "      <td>640</td>\n",
       "      <td>[3193, (Dear Falcons fans: are you guys ready ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>1:00</td>\n",
       "      <td>@</td>\n",
       "      <td>Buffalo Bills</td>\n",
       "      <td>W 21-12</td>\n",
       "      <td>W -7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6z90qu/g...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6z97il/g...</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6zajs1/p...</td>\n",
       "      <td>[240, (Bitter-sweet start to the NFL season wi...</td>\n",
       "      <td>[109, (I'm a Jets fan. I'm a Texas A&amp;M fan. Ye...</td>\n",
       "      <td>[120, (Bills number 1 seed in the AFCE!, 194),...</td>\n",
       "      <td>640</td>\n",
       "      <td>[109, (I'm a Jets fan. I'm a Texas A&amp;M fan. Ye...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  Week  Day       Date Time (ET) Unnamed: 5              Favorite  \\\n",
       "0    2017     1  Thu 2017-09-07      8:30          @  New England Patriots   \n",
       "1    2017     1  Sun 2017-09-10      1:00          @         Buffalo Bills   \n",
       "\n",
       "     Score Spread Unnamed: 9  ...  \\\n",
       "0  L 27-42   L -8        NaN  ...   \n",
       "1  W 21-12   W -7        NaN  ...   \n",
       "\n",
       "                                     GameHub/RedZone Game thread link?  \\\n",
       "0                                                NaN               NaN   \n",
       "1  https://www.reddit.com/r/nfl/comments/6z90qu/g...               NaN   \n",
       "\n",
       "  Post-game thread link?                                        Game thread  \\\n",
       "0                    NaN  https://www.reddit.com/r/nfl/comments/6yr619/g...   \n",
       "1                    1.0  https://www.reddit.com/r/nfl/comments/6z97il/g...   \n",
       "\n",
       "                                    Post game thread  \\\n",
       "0  https://www.reddit.com/r/nfl/comments/6ysc10/p...   \n",
       "1  https://www.reddit.com/r/nfl/comments/6zajs1/p...   \n",
       "\n",
       "                                     GameHub Scraped  \\\n",
       "0                                                NaN   \n",
       "1  [240, (Bitter-sweet start to the NFL season wi...   \n",
       "\n",
       "                                 Game thread scraped  \\\n",
       "0  [3193, (Dear Falcons fans: are you guys ready ...   \n",
       "1  [109, (I'm a Jets fan. I'm a Texas A&M fan. Ye...   \n",
       "\n",
       "                            Post game thread Scraped  \\\n",
       "0  [2781, (I'm imagining a world where the Patrio...   \n",
       "1  [120, (Bills number 1 seed in the AFCE!, 194),...   \n",
       "\n",
       "  Subscribers (in thousands)  \\\n",
       "0                        640   \n",
       "1                        640   \n",
       "\n",
       "                                        all comments  \n",
       "0  [3193, (Dear Falcons fans: are you guys ready ...  \n",
       "1  [109, (I'm a Jets fan. I'm a Texas A&M fan. Ye...  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "f94cd0ca-3a3c-4ba5-9444-d8250b944273",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, -1, 1]"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "def text_analyser(text):\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "    text = unmark(text).replace(\" \\n\",\" \")\n",
    "    text = convert_super_bowl(text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    sentiment_dict = sid_obj.polarity_scores(text)\n",
    "    if sentiment_dict['compound'] >= 0.05 :\n",
    "        return 1\n",
    "    elif sentiment_dict['compound'] <= - 0.05 :\n",
    "        return -1\n",
    "    else :\n",
    "        return 0\n",
    "\n",
    "def list_analyser(lst):\n",
    "    return [text_analyser(i[0]) for i in lst]\n",
    "    \n",
    "def prop_calculator(analysed_lst):\n",
    "    proportion_pos = analysed_lst.count(1) / len(analysed_lst)\n",
    "    proportion_neg = analysed_lst.count(-1) / len(analysed_lst)\n",
    "    return (proportion_pos, proportion_neg)\n",
    "\n",
    "alpha = list_analyser(reddit_df['all comments'][0])\n",
    "alpha[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "1e179e40-ef6f-425e-bfdf-c59aca461a45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3989547038327526, 0.29094076655052264)"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_calculator(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "805586a4-5f9b-4001-be29-31b877190a33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sentiment_func(row):\n",
    "    try:\n",
    "        return list_analyser(row['all comments'])\n",
    "    except ExceptionThatIVSometimesThrows as e:\n",
    "        return f\"Error on row {row.name}\"\n",
    "\n",
    "df = reddit_df.head(5).copy()\n",
    "df['test'] = df.apply(myfunc, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e463fa-7370-49e6-9b1e-b808b16b0487",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#reddit_df['sentiment_scores'] = reddit_df['all comments'].apply(list_analyser)\n",
    "reddit_df['sentiment_scores'] = reddit_df.apply(myfunc, axis=1)\n",
    "#reddit_df['props'] = reddit_df['sentiment_scores'].apply(prop_calculator)\n",
    "reddit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "3cf057b8-deb1-4cf0-bec9-3d066fda5e30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/rohanjha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import nltk.corpus\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "1d938155-ad86-45e4-9e04-182cd8e5387d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bosa',\n",
       " 'literally',\n",
       " 'gets',\n",
       " 'held',\n",
       " 'next',\n",
       " 'to',\n",
       " 'that',\n",
       " 'like',\n",
       " 'come',\n",
       " 'on']"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = word_tokenize(text)\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "92542450-e288-43be-8965-4e23c27732e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bosa', 'liter', 'get', 'held', 'next', 'to', 'that', 'like', 'come', 'on']"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "pst = PorterStemmer()\n",
    "stemmed_words = [pst.stem(x) for x in token]\n",
    "stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "fd65d85e-f2e9-482d-9970-56c80081e962",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rohanjha/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['bosa', 'liter', 'get', 'held', 'next', 'to', 'that', 'like', 'come', 'on']"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(x) for x in stemmed_words]\n",
    "lemmatized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "a3ff56ad-c3ff-4964-8925-9113564b6631",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bosa', 'liter', 'get', 'held', 'next', 'like', 'come']"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "a = set(stopwords.words('english'))\n",
    "no_stopwords = [x for x in lemmatized_words if x not in a]\n",
    "no_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "a0d43a2e-f49b-4f5b-8081-616b8ebad1df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Bosa', 'NNP')]\n",
      "[('literally', 'RB')]\n",
      "[('gets', 'VBZ')]\n",
      "[('held', 'NN')]\n",
      "[('next', 'JJ')]\n",
      "[('to', 'TO')]\n",
      "[('that', 'IN')]\n",
      "[('like', 'IN')]\n",
      "[('come', 'VB')]\n",
      "[('on', 'IN')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/rohanjha/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "for word in token:\n",
    "    print(nltk.pos_tag([word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "02237dfa-bdef-4e42-a88b-958384816862",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'bosa': 1, 'liter': 1, 'get': 1, 'held': 1, 'next': 1, 'like': 1, 'come': 1})"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist([pst.stem(x) for x in no_stopwords])\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c69cea-d209-4777-b52a-2de80a406edb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sklearn-env] *",
   "language": "python",
   "name": "conda-env-sklearn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
