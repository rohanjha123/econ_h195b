{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "d57b7666-214b-474a-adbc-542e72d94066",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "64c505db-aaed-4d3f-908d-537df4352fd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time (ET)</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Favorite</th>\n",
       "      <th>Score</th>\n",
       "      <th>Spread</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Notes</th>\n",
       "      <th>GameHub/RedZone</th>\n",
       "      <th>Game thread link?</th>\n",
       "      <th>Post-game thread link?</th>\n",
       "      <th>Game thread</th>\n",
       "      <th>Post game thread</th>\n",
       "      <th>GameHub Scraped</th>\n",
       "      <th>Game thread scraped</th>\n",
       "      <th>Post game thread Scraped</th>\n",
       "      <th>Subscribers (in thousands)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2017-09-07</td>\n",
       "      <td>8:30</td>\n",
       "      <td>@</td>\n",
       "      <td>New England Patriots</td>\n",
       "      <td>L 27-42</td>\n",
       "      <td>L -8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6yr619/g...</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6ysc10/p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[3193, ('Dear Falcons fans: are you guys ready...</td>\n",
       "      <td>[2781, ('I\\'m imagining a world where the Patr...</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>1:00</td>\n",
       "      <td>@</td>\n",
       "      <td>Buffalo Bills</td>\n",
       "      <td>W 21-12</td>\n",
       "      <td>W -7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6z90qu/g...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6z97il/g...</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6zajs1/p...</td>\n",
       "      <td>[240, ('Bitter-sweet start to the NFL season w...</td>\n",
       "      <td>[109, ('I\\'m a Jets fan. I\\'m a Texas A&amp;M fan....</td>\n",
       "      <td>[120, ('Bills number 1 seed in the AFCE!', 194...</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>1:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlanta Falcons</td>\n",
       "      <td>W 23-17</td>\n",
       "      <td>L -6.5</td>\n",
       "      <td>@</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6z90qu/g...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6z97gn/g...</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6zajuc/p...</td>\n",
       "      <td>[240, ('Bitter-sweet start to the NFL season w...</td>\n",
       "      <td>[321, ('Wow this national anthem singer is a f...</td>\n",
       "      <td>[351, (\"We just went down to the wire against ...</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>1:00</td>\n",
       "      <td>@</td>\n",
       "      <td>Cincinnati Bengals</td>\n",
       "      <td>L 0-20</td>\n",
       "      <td>L -2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6z90qu/g...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6z97hl/g...</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6zajr0/p...</td>\n",
       "      <td>[240, ('Bitter-sweet start to the NFL season w...</td>\n",
       "      <td>[192, (\"Man I hope Woodhead stays healthy for ...</td>\n",
       "      <td>[293, ('[Summary of this game](https://pbs.twi...</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>Sun</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>1:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pittsburgh Steelers</td>\n",
       "      <td>W 21-18</td>\n",
       "      <td>L -10</td>\n",
       "      <td>@</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6z90qu/g...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6z97l9/g...</td>\n",
       "      <td>https://www.reddit.com/r/nfl/comments/6zajwi/p...</td>\n",
       "      <td>[240, ('Bitter-sweet start to the NFL season w...</td>\n",
       "      <td>[367, (\"1 drive no turnovers. WE'VE TURNED THE...</td>\n",
       "      <td>[383, (\"Don't let this distract you from the f...</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season  Week  Day       Date Time (ET) Unnamed: 5              Favorite  \\\n",
       "0    2017     1  Thu 2017-09-07      8:30          @  New England Patriots   \n",
       "1    2017     1  Sun 2017-09-10      1:00          @         Buffalo Bills   \n",
       "2    2017     1  Sun 2017-09-10      1:00        NaN       Atlanta Falcons   \n",
       "3    2017     1  Sun 2017-09-10      1:00          @    Cincinnati Bengals   \n",
       "4    2017     1  Sun 2017-09-10      1:00        NaN   Pittsburgh Steelers   \n",
       "\n",
       "     Score  Spread Unnamed: 9  ... Notes  \\\n",
       "0  L 27-42    L -8        NaN  ...   NaN   \n",
       "1  W 21-12    W -7        NaN  ...   NaN   \n",
       "2  W 23-17  L -6.5          @  ...   NaN   \n",
       "3   L 0-20  L -2.5        NaN  ...   NaN   \n",
       "4  W 21-18   L -10          @  ...   NaN   \n",
       "\n",
       "                                     GameHub/RedZone Game thread link?  \\\n",
       "0                                                NaN               NaN   \n",
       "1  https://www.reddit.com/r/nfl/comments/6z90qu/g...               NaN   \n",
       "2  https://www.reddit.com/r/nfl/comments/6z90qu/g...               NaN   \n",
       "3  https://www.reddit.com/r/nfl/comments/6z90qu/g...               NaN   \n",
       "4  https://www.reddit.com/r/nfl/comments/6z90qu/g...               NaN   \n",
       "\n",
       "  Post-game thread link?                                        Game thread  \\\n",
       "0                    NaN  https://www.reddit.com/r/nfl/comments/6yr619/g...   \n",
       "1                    1.0  https://www.reddit.com/r/nfl/comments/6z97il/g...   \n",
       "2                    1.0  https://www.reddit.com/r/nfl/comments/6z97gn/g...   \n",
       "3                    1.0  https://www.reddit.com/r/nfl/comments/6z97hl/g...   \n",
       "4                    1.0  https://www.reddit.com/r/nfl/comments/6z97l9/g...   \n",
       "\n",
       "                                    Post game thread  \\\n",
       "0  https://www.reddit.com/r/nfl/comments/6ysc10/p...   \n",
       "1  https://www.reddit.com/r/nfl/comments/6zajs1/p...   \n",
       "2  https://www.reddit.com/r/nfl/comments/6zajuc/p...   \n",
       "3  https://www.reddit.com/r/nfl/comments/6zajr0/p...   \n",
       "4  https://www.reddit.com/r/nfl/comments/6zajwi/p...   \n",
       "\n",
       "                                     GameHub Scraped  \\\n",
       "0                                                NaN   \n",
       "1  [240, ('Bitter-sweet start to the NFL season w...   \n",
       "2  [240, ('Bitter-sweet start to the NFL season w...   \n",
       "3  [240, ('Bitter-sweet start to the NFL season w...   \n",
       "4  [240, ('Bitter-sweet start to the NFL season w...   \n",
       "\n",
       "                                 Game thread scraped  \\\n",
       "0  [3193, ('Dear Falcons fans: are you guys ready...   \n",
       "1  [109, ('I\\'m a Jets fan. I\\'m a Texas A&M fan....   \n",
       "2  [321, ('Wow this national anthem singer is a f...   \n",
       "3  [192, (\"Man I hope Woodhead stays healthy for ...   \n",
       "4  [367, (\"1 drive no turnovers. WE'VE TURNED THE...   \n",
       "\n",
       "                            Post game thread Scraped  \\\n",
       "0  [2781, ('I\\'m imagining a world where the Patr...   \n",
       "1  [120, ('Bills number 1 seed in the AFCE!', 194...   \n",
       "2  [351, (\"We just went down to the wire against ...   \n",
       "3  [293, ('[Summary of this game](https://pbs.twi...   \n",
       "4  [383, (\"Don't let this distract you from the f...   \n",
       "\n",
       "  Subscribers (in thousands)  \n",
       "0                        640  \n",
       "1                        640  \n",
       "2                        640  \n",
       "3                        640  \n",
       "4                        640  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with zipfile.ZipFile(\"../data/reddit_scrape.csv.zip\") as z:\n",
    "    with z.open(\"reddit_scrape.csv\") as f:\n",
    "        reddit_df = pd.read_csv(f)\n",
    "\n",
    "reddit_df['Date'] = pd.to_datetime(reddit_df['Date'])    \n",
    "\n",
    "reddit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "4b970f37-39db-42b7-ab62-85c0737ee01c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scrape_cols = [x for x in reddit_df.columns if 'craped' in x]\n",
    "for col in scrape_cols: # converts strings to lists\n",
    "    reddit_df[col] = reddit_df[col].apply(lambda x: eval(x) if type(x)==str else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "9772ce21-6e95-445e-a475-5a8d4667ddb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dear Falcons fans: are you guys ready for 17 straight weeks of hearing how you fucked up the Super Bowl? I feel your pain. \\n\\nSincerely, \\n\\n\\nSeahawks fans everywhere.'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = reddit_df['Game thread scraped'][0][1][0]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "810ee356-ef80-412e-ab39-6e744c46b7ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dear Falcons fans: are you guys ready for 17 straight weeks of hearing how you fucked up the Super Bowl? I feel your pain. Sincerely, Seahawks fans everywhere.'"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from markdown import Markdown\n",
    "from io import StringIO\n",
    "\n",
    "\n",
    "def unmark_element(element, stream=None):\n",
    "    if stream is None:\n",
    "        stream = StringIO()\n",
    "    if element.text:\n",
    "        stream.write(element.text)\n",
    "    for sub in element:\n",
    "        unmark_element(sub, stream)\n",
    "    if element.tail:\n",
    "        stream.write(element.tail)\n",
    "    return stream.getvalue()\n",
    "\n",
    "\n",
    "# patching Markdown\n",
    "Markdown.output_formats[\"plain\"] = unmark_element\n",
    "__md = Markdown(output_format=\"plain\")\n",
    "__md.stripTopLevelTags = False\n",
    "\n",
    "\n",
    "def unmark(text):\n",
    "    return __md.convert(text).replace(\" \\n\",\" \")\n",
    "\n",
    "text = unmark(text).replace(\" \\n\",\" \")\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "270f197d-eaf5-4f9f-a449-e163043dd3c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dear Falcons fans are you guys ready for 17 straight weeks of hearing how you fucked up the Super Bowl I feel your pain Sincerely Seahawks fans everywhere'"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "d348f4ad-c29f-41b4-86e6-f2d50858d561",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m202.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /Users/rohanjha/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from vaderSentiment) (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/rohanjha/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from requests->vaderSentiment) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rohanjha/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from requests->vaderSentiment) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/rohanjha/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from requests->vaderSentiment) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rohanjha/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from requests->vaderSentiment) (2022.12.7)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "bc94fff5-0b4f-40e5-912e-ec836ec09015",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "5212fb01-3e98-4894-80b3-21b5ddb68ae2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sentiment_scores(sentence):\n",
    "    # Create a SentimentIntensityAnalyzer object.\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "    # polarity_scores method of SentimentIntensityAnalyzer\n",
    "    # oject gives a sentiment dictionary.\n",
    "    # which contains pos, neg, neu, and compound scores.\n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "    print(\"Overall sentiment dictionary is : \", sentiment_dict)\n",
    "    print(\"sentence was rated as \", sentiment_dict['neg']*100, \"% Negative\")\n",
    "    print(\"sentence was rated as \", sentiment_dict['neu']*100, \"% Neutral\")\n",
    "    print(\"sentence was rated as \", sentiment_dict['pos']*100, \"% Positive\")\n",
    "    print(\"Sentence Overall Rated As\", end = \" \")\n",
    "    # decide sentiment as positive, negative and neutral\n",
    "    if sentiment_dict['compound'] >= 0.05 :\n",
    "        print(\"Positive\")\n",
    "    elif sentiment_dict['compound'] <= - 0.05 :\n",
    "        print(\"Negative\")\n",
    "    else :\n",
    "        print(\"Neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "7cf38b27-677a-44b0-96bc-d44d7bf60b2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall sentiment dictionary is :  {'neg': 0.18, 'neu': 0.492, 'pos': 0.328, 'compound': 0.6486}\n",
      "sentence was rated as  18.0 % Negative\n",
      "sentence was rated as  49.2 % Neutral\n",
      "sentence was rated as  32.800000000000004 % Positive\n",
      "Sentence Overall Rated As Positive\n"
     ]
    }
   ],
   "source": [
    "sentiment_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "6880eb6b-21df-45f6-8ee1-cb8798c600f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Fuckin Mark Wahlberg LEFT THE SUPER BOWL EARLY BECAUSE THE PATS WERE DOWN 28-3\n",
      "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 0.737, 'pos': 0.263, 'compound': 0.6841}\n",
      "sentence was rated as  0.0 % Negative\n",
      "sentence was rated as  73.7 % Neutral\n",
      "sentence was rated as  26.3 % Positive\n",
      "Sentence Overall Rated As Positive\n"
     ]
    }
   ],
   "source": [
    "text = reddit_df['Game thread scraped'][0][2][0]\n",
    "print(text)\n",
    "text = unmark(text).replace(\" \\n\",\" \")\n",
    "text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "sentiment_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "9daea5bb-5f7f-49ca-943d-f4313ca6df89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SuperBowl is a great event.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def convert_super_bowl(text):\n",
    "    # Use regular expression to find and replace \"super bowl\" with \"superbowl\" (case-insensitive)\n",
    "    modified_text = re.sub(r'\\b(super)\\s+(bowl)\\b', r'\\1\\2', text, flags=re.IGNORECASE)\n",
    "    return modified_text\n",
    "\n",
    "# Example usage:\n",
    "original_text = \"The Super Bowl is a great event.\"\n",
    "converted_text = convert_super_bowl(original_text)\n",
    "print(converted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "c81fda98-6cc0-4330-82ad-98e5701741d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "thread_num = []\n",
    "comment_num = []\n",
    "comments = []\n",
    "pos_words = []\n",
    "neu_words = []\n",
    "neg_words = []\n",
    "scores = []\n",
    "overall_rating = []\n",
    "\n",
    "for i in range(10):\n",
    "    num_1 = random.randrange(len(reddit_df))\n",
    "    for j in range(50):\n",
    "        thread_num.append(num_1)\n",
    "        num_2 = random.randrange(len(reddit_df.iloc[num_1,:].loc['Game thread scraped']))\n",
    "        if j != 0:\n",
    "            while num_2 in comment_num[-j:]:\n",
    "                num_2 = random.randrange(len(reddit_df.iloc[num_1,:].loc['Game thread scraped']))\n",
    "        comment_num.append(num_2)\n",
    "        text = reddit_df['Game thread scraped'][num_1][num_2][0]\n",
    "        # print(text)\n",
    "        # print(\"____________________________________________________________________________________________________\")\n",
    "        comments.append(text)\n",
    "        text = unmark(text).replace(\" \\n\",\" \")\n",
    "        text = convert_super_bowl(text)\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "        from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "        tokenized_sentence = nltk.word_tokenize(text)\n",
    "\n",
    "        sid = SentimentIntensityAnalyzer()\n",
    "        pos_word_list=[]\n",
    "        neu_word_list=[]\n",
    "        neg_word_list=[]\n",
    "\n",
    "        for word in tokenized_sentence:\n",
    "            if (sid.polarity_scores(word)['compound']) >= 0.05:\n",
    "                pos_word_list.append(word)\n",
    "            elif (sid.polarity_scores(word)['compound']) <= -0.05:\n",
    "                neg_word_list.append(word)\n",
    "            else:\n",
    "                neu_word_list.append(word)                \n",
    "\n",
    "        # print('Positive:', pos_word_list) \n",
    "        pos_words.append(pos_word_list)\n",
    "        # print('Neutral:', neu_word_list) \n",
    "        neu_words.append(neu_word_list)\n",
    "        # print('Negative:', neg_word_list) \n",
    "        neg_words.append(neg_word_list)\n",
    "        score = sid.polarity_scores(text)\n",
    "        # print('\\nScores:', score,\"\\n\")\n",
    "        scores.append(score)\n",
    "        # print(\"Sentence Overall Rated As\", end = \" \")\n",
    "        if score['compound'] >= 0.05 :\n",
    "            # print(\"Positive\")\n",
    "            overall_rating.append(1)\n",
    "        elif score['compound'] <= - 0.05 :\n",
    "            # print(\"Negative\")\n",
    "            overall_rating.append(-1)\n",
    "        else :\n",
    "            # print(\"Neutral\")\n",
    "            overall_rating.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "f001525f-d093-4116-bb5f-6d798fc0196b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Thread</th>\n",
       "      <th>Comment Number</th>\n",
       "      <th>Comment Text</th>\n",
       "      <th>Positive Words</th>\n",
       "      <th>Neutral Words</th>\n",
       "      <th>Negative Words</th>\n",
       "      <th>Scores</th>\n",
       "      <th>Overall Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220</td>\n",
       "      <td>251</td>\n",
       "      <td>He broke crossed the line and had control. How...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[He, crossed, the, line, and, had, control, Ho...</td>\n",
       "      <td>[broke, lose]</td>\n",
       "      <td>{'neg': 0.103, 'neu': 0.813, 'pos': 0.083, 'co...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220</td>\n",
       "      <td>396</td>\n",
       "      <td>There were multiple Patriots not lined up prop...</td>\n",
       "      <td>[play, like]</td>\n",
       "      <td>[There, were, multiple, Patriots, not, lined, ...</td>\n",
       "      <td>[miss]</td>\n",
       "      <td>{'neg': 0.056, 'neu': 0.772, 'pos': 0.172, 'co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220</td>\n",
       "      <td>52</td>\n",
       "      <td>THIS WEEK ON WHAT IS A CATCH</td>\n",
       "      <td>[]</td>\n",
       "      <td>[THIS, WEEK, ON, WHAT, IS, A, CATCH]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220</td>\n",
       "      <td>420</td>\n",
       "      <td>8 is neither 5 or 6. Good job D.</td>\n",
       "      <td>[Good]</td>\n",
       "      <td>[8, is, neither, 5, or, 6, job, D]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'neg': 0.376, 'neu': 0.624, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220</td>\n",
       "      <td>283</td>\n",
       "      <td>That's a catch. Don't care what the rules say.</td>\n",
       "      <td>[care]</td>\n",
       "      <td>[Thats, a, catch, Dont, what, the, rules, say]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'neg': 0.273, 'neu': 0.727, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>55</td>\n",
       "      <td>189</td>\n",
       "      <td>Wanna know what's gonna happen? Carolina is go...</td>\n",
       "      <td>[win]</td>\n",
       "      <td>[Wan, na, know, whats, gon, na, happen, Caroli...</td>\n",
       "      <td>[fuck, wrong, forgotten]</td>\n",
       "      <td>{'neg': 0.134, 'neu': 0.806, 'pos': 0.06, 'com...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>55</td>\n",
       "      <td>403</td>\n",
       "      <td>I'm loving these TD celebrations. Glad they're...</td>\n",
       "      <td>[loving, Glad]</td>\n",
       "      <td>[Im, these, TD, celebrations, theyre, back]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.465, 'pos': 0.535, 'comp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>Love this hate Patriot fans.</td>\n",
       "      <td>[Love]</td>\n",
       "      <td>[this, Patriot, fans]</td>\n",
       "      <td>[hate]</td>\n",
       "      <td>{'neg': 0.339, 'neu': 0.275, 'pos': 0.385, 'co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>55</td>\n",
       "      <td>215</td>\n",
       "      <td>STEPHEN GOSTKOWSKI IS STILL PERFECT THIS MONTH!</td>\n",
       "      <td>[PERFECT]</td>\n",
       "      <td>[STEPHEN, GOSTKOWSKI, IS, STILL, THIS, MONTH]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.619, 'pos': 0.381, 'comp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>55</td>\n",
       "      <td>281</td>\n",
       "      <td>Late hits are okay. Touching anyone in passing...</td>\n",
       "      <td>[okay, plays]</td>\n",
       "      <td>[Late, hits, are, Touching, anyone, in, passin...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.698, 'pos': 0.302, 'comp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Thread  Comment Number  \\\n",
       "0       220             251   \n",
       "1       220             396   \n",
       "2       220              52   \n",
       "3       220             420   \n",
       "4       220             283   \n",
       "..      ...             ...   \n",
       "495      55             189   \n",
       "496      55             403   \n",
       "497      55              50   \n",
       "498      55             215   \n",
       "499      55             281   \n",
       "\n",
       "                                          Comment Text  Positive Words  \\\n",
       "0    He broke crossed the line and had control. How...              []   \n",
       "1    There were multiple Patriots not lined up prop...    [play, like]   \n",
       "2                        THIS WEEK ON WHAT IS A CATCH               []   \n",
       "3                     8 is neither 5 or 6. Good job D.          [Good]   \n",
       "4       That's a catch. Don't care what the rules say.          [care]   \n",
       "..                                                 ...             ...   \n",
       "495  Wanna know what's gonna happen? Carolina is go...           [win]   \n",
       "496  I'm loving these TD celebrations. Glad they're...  [loving, Glad]   \n",
       "497                       Love this hate Patriot fans.          [Love]   \n",
       "498    STEPHEN GOSTKOWSKI IS STILL PERFECT THIS MONTH!       [PERFECT]   \n",
       "499  Late hits are okay. Touching anyone in passing...   [okay, plays]   \n",
       "\n",
       "                                         Neutral Words  \\\n",
       "0    [He, crossed, the, line, and, had, control, Ho...   \n",
       "1    [There, were, multiple, Patriots, not, lined, ...   \n",
       "2                 [THIS, WEEK, ON, WHAT, IS, A, CATCH]   \n",
       "3                   [8, is, neither, 5, or, 6, job, D]   \n",
       "4       [Thats, a, catch, Dont, what, the, rules, say]   \n",
       "..                                                 ...   \n",
       "495  [Wan, na, know, whats, gon, na, happen, Caroli...   \n",
       "496        [Im, these, TD, celebrations, theyre, back]   \n",
       "497                              [this, Patriot, fans]   \n",
       "498      [STEPHEN, GOSTKOWSKI, IS, STILL, THIS, MONTH]   \n",
       "499  [Late, hits, are, Touching, anyone, in, passin...   \n",
       "\n",
       "               Negative Words  \\\n",
       "0               [broke, lose]   \n",
       "1                      [miss]   \n",
       "2                          []   \n",
       "3                          []   \n",
       "4                          []   \n",
       "..                        ...   \n",
       "495  [fuck, wrong, forgotten]   \n",
       "496                        []   \n",
       "497                    [hate]   \n",
       "498                        []   \n",
       "499                        []   \n",
       "\n",
       "                                                Scores  Overall Rating  \n",
       "0    {'neg': 0.103, 'neu': 0.813, 'pos': 0.083, 'co...              -1  \n",
       "1    {'neg': 0.056, 'neu': 0.772, 'pos': 0.172, 'co...               1  \n",
       "2    {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...               0  \n",
       "3    {'neg': 0.376, 'neu': 0.624, 'pos': 0.0, 'comp...              -1  \n",
       "4    {'neg': 0.273, 'neu': 0.727, 'pos': 0.0, 'comp...              -1  \n",
       "..                                                 ...             ...  \n",
       "495  {'neg': 0.134, 'neu': 0.806, 'pos': 0.06, 'com...              -1  \n",
       "496  {'neg': 0.0, 'neu': 0.465, 'pos': 0.535, 'comp...               1  \n",
       "497  {'neg': 0.339, 'neu': 0.275, 'pos': 0.385, 'co...               1  \n",
       "498  {'neg': 0.0, 'neu': 0.619, 'pos': 0.381, 'comp...               1  \n",
       "499  {'neg': 0.0, 'neu': 0.698, 'pos': 0.302, 'comp...               1  \n",
       "\n",
       "[500 rows x 8 columns]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"Thread\": thread_num,\n",
    "    \"Comment Number\": comment_num,\n",
    "    'Comment Text': comments,\n",
    "    'Positive Words': pos_words,\n",
    "    'Neutral Words': neu_words,\n",
    "    'Negative Words': neg_words,\n",
    "    'Scores': scores,\n",
    "    'Overall Rating': overall_rating\n",
    "}\n",
    "\n",
    "verifying_df = pd.DataFrame(data)\n",
    "verifying_df#.to_csv('verifying_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "a12afac8-1ff5-4b0b-a20b-7c68417faab6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.0     33\n",
      " 0.0     21\n",
      "-99.0    12\n",
      " 0.5      3\n",
      "Name: Accurate, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Thread</th>\n",
       "      <th>Comment Number</th>\n",
       "      <th>Comment Text</th>\n",
       "      <th>Positive Words</th>\n",
       "      <th>Neutral Words</th>\n",
       "      <th>Negative Words</th>\n",
       "      <th>Scores</th>\n",
       "      <th>Overall Rating</th>\n",
       "      <th>My rating</th>\n",
       "      <th>Compound</th>\n",
       "      <th>Accurate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220</td>\n",
       "      <td>251</td>\n",
       "      <td>He broke crossed the line and had control. How...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['He', 'crossed', 'the', 'line', 'and', 'had',...</td>\n",
       "      <td>['broke', 'lose']</td>\n",
       "      <td>{'neg': 0.103, 'neu': 0.813, 'pos': 0.083, 'co...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.1386</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220</td>\n",
       "      <td>396</td>\n",
       "      <td>There were multiple Patriots not lined up prop...</td>\n",
       "      <td>['play', 'like']</td>\n",
       "      <td>['There', 'were', 'multiple', 'Patriots', 'not...</td>\n",
       "      <td>['miss']</td>\n",
       "      <td>{'neg': 0.056, 'neu': 0.772, 'pos': 0.172, 'co...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220</td>\n",
       "      <td>52</td>\n",
       "      <td>THIS WEEK ON WHAT IS A CATCH</td>\n",
       "      <td>[]</td>\n",
       "      <td>['THIS', 'WEEK', 'ON', 'WHAT', 'IS', 'A', 'CAT...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220</td>\n",
       "      <td>420</td>\n",
       "      <td>8 is neither 5 or 6. Good job D.</td>\n",
       "      <td>['Good']</td>\n",
       "      <td>['8', 'is', 'neither', '5', 'or', '6', 'job', ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'neg': 0.376, 'neu': 0.624, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-0.3412</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220</td>\n",
       "      <td>283</td>\n",
       "      <td>That's a catch. Don't care what the rules say.</td>\n",
       "      <td>['care']</td>\n",
       "      <td>['Thats', 'a', 'catch', 'Dont', 'what', 'the',...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'neg': 0.273, 'neu': 0.727, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.3875</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>55</td>\n",
       "      <td>189</td>\n",
       "      <td>Wanna know what's gonna happen? Carolina is go...</td>\n",
       "      <td>['win']</td>\n",
       "      <td>['Wan', 'na', 'know', 'whats', 'gon', 'na', 'h...</td>\n",
       "      <td>['fuck', 'wrong', 'forgotten']</td>\n",
       "      <td>{'neg': 0.134, 'neu': 0.806, 'pos': 0.06, 'com...</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.5719</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>55</td>\n",
       "      <td>403</td>\n",
       "      <td>I'm loving these TD celebrations. Glad they're...</td>\n",
       "      <td>['loving', 'Glad']</td>\n",
       "      <td>['Im', 'these', 'TD', 'celebrations', 'theyre'...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.465, 'pos': 0.535, 'comp...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>Love this hate Patriot fans.</td>\n",
       "      <td>['Love']</td>\n",
       "      <td>['this', 'Patriot', 'fans']</td>\n",
       "      <td>['hate']</td>\n",
       "      <td>{'neg': 0.339, 'neu': 0.275, 'pos': 0.385, 'co...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>55</td>\n",
       "      <td>215</td>\n",
       "      <td>STEPHEN GOSTKOWSKI IS STILL PERFECT THIS MONTH!</td>\n",
       "      <td>['PERFECT']</td>\n",
       "      <td>['STEPHEN', 'GOSTKOWSKI', 'IS', 'STILL', 'THIS...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.619, 'pos': 0.381, 'comp...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>55</td>\n",
       "      <td>281</td>\n",
       "      <td>Late hits are okay. Touching anyone in passing...</td>\n",
       "      <td>['okay', 'plays']</td>\n",
       "      <td>['Late', 'hits', 'are', 'Touching', 'anyone', ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.698, 'pos': 0.302, 'comp...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>496 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Thread  Comment Number  \\\n",
       "0       220             251   \n",
       "1       220             396   \n",
       "2       220              52   \n",
       "3       220             420   \n",
       "4       220             283   \n",
       "..      ...             ...   \n",
       "491      55             189   \n",
       "492      55             403   \n",
       "493      55              50   \n",
       "494      55             215   \n",
       "495      55             281   \n",
       "\n",
       "                                          Comment Text      Positive Words  \\\n",
       "0    He broke crossed the line and had control. How...                  []   \n",
       "1    There were multiple Patriots not lined up prop...    ['play', 'like']   \n",
       "2                        THIS WEEK ON WHAT IS A CATCH                   []   \n",
       "3                     8 is neither 5 or 6. Good job D.            ['Good']   \n",
       "4       That's a catch. Don't care what the rules say.            ['care']   \n",
       "..                                                 ...                 ...   \n",
       "491  Wanna know what's gonna happen? Carolina is go...             ['win']   \n",
       "492  I'm loving these TD celebrations. Glad they're...  ['loving', 'Glad']   \n",
       "493                       Love this hate Patriot fans.            ['Love']   \n",
       "494    STEPHEN GOSTKOWSKI IS STILL PERFECT THIS MONTH!         ['PERFECT']   \n",
       "495  Late hits are okay. Touching anyone in passing...   ['okay', 'plays']   \n",
       "\n",
       "                                         Neutral Words  \\\n",
       "0    ['He', 'crossed', 'the', 'line', 'and', 'had',...   \n",
       "1    ['There', 'were', 'multiple', 'Patriots', 'not...   \n",
       "2    ['THIS', 'WEEK', 'ON', 'WHAT', 'IS', 'A', 'CAT...   \n",
       "3    ['8', 'is', 'neither', '5', 'or', '6', 'job', ...   \n",
       "4    ['Thats', 'a', 'catch', 'Dont', 'what', 'the',...   \n",
       "..                                                 ...   \n",
       "491  ['Wan', 'na', 'know', 'whats', 'gon', 'na', 'h...   \n",
       "492  ['Im', 'these', 'TD', 'celebrations', 'theyre'...   \n",
       "493                        ['this', 'Patriot', 'fans']   \n",
       "494  ['STEPHEN', 'GOSTKOWSKI', 'IS', 'STILL', 'THIS...   \n",
       "495  ['Late', 'hits', 'are', 'Touching', 'anyone', ...   \n",
       "\n",
       "                     Negative Words  \\\n",
       "0                 ['broke', 'lose']   \n",
       "1                          ['miss']   \n",
       "2                                []   \n",
       "3                                []   \n",
       "4                                []   \n",
       "..                              ...   \n",
       "491  ['fuck', 'wrong', 'forgotten']   \n",
       "492                              []   \n",
       "493                        ['hate']   \n",
       "494                              []   \n",
       "495                              []   \n",
       "\n",
       "                                                Scores  Overall Rating  \\\n",
       "0    {'neg': 0.103, 'neu': 0.813, 'pos': 0.083, 'co...              -1   \n",
       "1    {'neg': 0.056, 'neu': 0.772, 'pos': 0.172, 'co...               1   \n",
       "2    {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...               0   \n",
       "3    {'neg': 0.376, 'neu': 0.624, 'pos': 0.0, 'comp...              -1   \n",
       "4    {'neg': 0.273, 'neu': 0.727, 'pos': 0.0, 'comp...              -1   \n",
       "..                                                 ...             ...   \n",
       "491  {'neg': 0.134, 'neu': 0.806, 'pos': 0.06, 'com...              -1   \n",
       "492  {'neg': 0.0, 'neu': 0.465, 'pos': 0.535, 'comp...               1   \n",
       "493  {'neg': 0.339, 'neu': 0.275, 'pos': 0.385, 'co...               1   \n",
       "494  {'neg': 0.0, 'neu': 0.619, 'pos': 0.381, 'comp...               1   \n",
       "495  {'neg': 0.0, 'neu': 0.698, 'pos': 0.302, 'comp...               1   \n",
       "\n",
       "     My rating  Compound  Accurate  \n",
       "0         -1.0   -0.1386       1.0  \n",
       "1         -1.0    0.5106       0.0  \n",
       "2          0.0    0.0000       0.5  \n",
       "3        -99.0   -0.3412     -99.0  \n",
       "4          1.0   -0.3875       0.0  \n",
       "..         ...       ...       ...  \n",
       "491        NaN   -0.5719       NaN  \n",
       "492        NaN    0.7845       NaN  \n",
       "493        NaN    0.1280       NaN  \n",
       "494        NaN    0.5719       NaN  \n",
       "495        NaN    0.4404       NaN  \n",
       "\n",
       "[496 rows x 11 columns]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('verifying_scores.csv').iloc[:,1:]\n",
    "def cutoffs(lower_bound, upper_bound, col):\n",
    "    lst = []\n",
    "    for i in col:\n",
    "        if i <= lower_bound:\n",
    "            lst.append(-1)\n",
    "        elif i >= upper_bound:\n",
    "            lst.append(1)\n",
    "        else:\n",
    "            lst.append(0)\n",
    "    return lst\n",
    "df['Scores'] = df['Scores'].apply(eval)\n",
    "df['Compound'] = [i['compound'] for i in df['Scores']]\n",
    "#df['Overall Rating'] = cutoffs(-0.05, 0.05,df['Compound'])\n",
    "df['Accurate'] = (df['My rating'] == df['Overall Rating']).astype(int)\n",
    "df.loc[df['Overall Rating'] == 0, 'Accurate'] = df.loc[df['Overall Rating'] == 0, 'Accurate']/2\n",
    "df.loc[df['My rating'] == -99, 'Accurate'] = -99\n",
    "df.loc[df['My rating'].isna(), 'Accurate'] = np.NaN\n",
    "print(df['Accurate'].value_counts())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "3cf057b8-deb1-4cf0-bec9-3d066fda5e30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/rohanjha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import nltk.corpus\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "1d938155-ad86-45e4-9e04-182cd8e5387d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bosa',\n",
       " 'literally',\n",
       " 'gets',\n",
       " 'held',\n",
       " 'next',\n",
       " 'to',\n",
       " 'that',\n",
       " 'like',\n",
       " 'come',\n",
       " 'on']"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = word_tokenize(text)\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "92542450-e288-43be-8965-4e23c27732e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bosa', 'liter', 'get', 'held', 'next', 'to', 'that', 'like', 'come', 'on']"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "pst = PorterStemmer()\n",
    "stemmed_words = [pst.stem(x) for x in token]\n",
    "stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "fd65d85e-f2e9-482d-9970-56c80081e962",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rohanjha/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['bosa', 'liter', 'get', 'held', 'next', 'to', 'that', 'like', 'come', 'on']"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(x) for x in stemmed_words]\n",
    "lemmatized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "a3ff56ad-c3ff-4964-8925-9113564b6631",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bosa', 'liter', 'get', 'held', 'next', 'like', 'come']"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "a = set(stopwords.words('english'))\n",
    "no_stopwords = [x for x in lemmatized_words if x not in a]\n",
    "no_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "a0d43a2e-f49b-4f5b-8081-616b8ebad1df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Bosa', 'NNP')]\n",
      "[('literally', 'RB')]\n",
      "[('gets', 'VBZ')]\n",
      "[('held', 'NN')]\n",
      "[('next', 'JJ')]\n",
      "[('to', 'TO')]\n",
      "[('that', 'IN')]\n",
      "[('like', 'IN')]\n",
      "[('come', 'VB')]\n",
      "[('on', 'IN')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/rohanjha/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "for word in token:\n",
    "    print(nltk.pos_tag([word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "02237dfa-bdef-4e42-a88b-958384816862",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'bosa': 1, 'liter': 1, 'get': 1, 'held': 1, 'next': 1, 'like': 1, 'come': 1})"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist([pst.stem(x) for x in no_stopwords])\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c69cea-d209-4777-b52a-2de80a406edb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sklearn-env] *",
   "language": "python",
   "name": "conda-env-sklearn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
